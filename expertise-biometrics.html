<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  <title>Biometrics & Multimodal Authentication - Venu Govindaraju</title>

  <meta name="description"
    content="Biometric and multimodal authentication expertise of Venu Siddapura Govindaraju – lip–audio authentication (BIOVID) and fingerprint liveness detection (LivDet 2025).">
  <meta name="keywords"
    content="biometrics, liveness detection, multimodal authentication, lip audio, ECAPA-TDNN, ResNet3D, GMU fusion, open-set verification, fingerprint, adversarial training, LivDet 2025, Venu Govindaraju">

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Fonts -->
  <link href="https://fonts.googleapis.com" rel="preconnect">
  <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
  <link
    href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700;900&family=Raleway:wght@300;400;500;600;700;800&family=Mulish:wght@300;400;500;600;700;800&display=swap"
    rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Main CSS File -->
  <link href="assets/css/main.css" rel="stylesheet">
</head>

<body class="service-details-page">

  <!-- Header -->
  <header id="header" class="header d-flex align-items-center sticky-top">
    <div class="container-fluid container-xl position-relative d-flex align-items-center">

      <a href="index.html" class="logo d-flex align-items-center me-auto">
        <h1 class="sitename">Venu Govindaraju</h1>
      </a>

      <nav id="navmenu" class="navmenu">
        <ul>
          <li><a href="index.html#hero">Home</a></li>
          <li><a href="index.html#about">About</a></li>
          <li><a href="index.html#resume">Experience</a></li>
          <li><a href="index.html#services">Expertise</a></li>
          <li><a href="index.html#portfolio">Projects</a></li>
          <li><a href="index.html#contact">Contact</a></li>
        </ul>
        <i class="mobile-nav-toggle d-xl-none bi bi-list"></i>
      </nav>

      <a class="btn-getstarted" href="index.html#contact">Let’s Connect</a>

    </div>
  </header>
  <!-- End Header -->

  <main class="main">

    <!-- Page Title -->
    <div class="page-title light-background">
      <div class="container">
        <nav class="breadcrumbs">
          <ol>
            <li><a href="index.html">Home</a></li>
            <li><a href="index.html#services">Expertise</a></li>
            <li class="current">Biometrics &amp; Multimodal Authentication</li>
          </ol>
        </nav>
        <h1>Biometrics &amp; Multimodal Authentication</h1>
      </div>
    </div>
    <!-- End Page Title -->

    <section id="service-details" class="service-details section">
      <div class="container" data-aos="fade-up" data-aos-delay="100">

        <div class="row">

          <!-- Sidebar -->
          <div class="col-lg-4 order-lg-2">
            <div class="sticky-sidebar">

              <!-- Role Fit Card -->
              <div class="service-card" data-aos="fade-left" data-aos-delay="200">
                <div class="card-header">
                  <div class="service-icon">
                    <i class="bi bi-shield-lock"></i>
                  </div>
                  <h3>Biometrics &amp; Security Profile</h3>
                  <p class="service-tagline">
                    Proven track record in <strong>two flagship biometric systems</strong>:
                    BIOVID lip–audio authentication and LivDet 2025 fingerprint liveness &amp; IMS.
                  </p>
                </div>
                <div class="card-body">
                  <ul class="quick-info">
                    <li>
                      <i class="bi bi-check-circle"></i>
                      <span>End-to-end design of lip–audio user verification for BIOVID 2025.</span>
                    </li>
                    <li>
                      <i class="bi bi-check-circle"></i>
                      <span>Adversarially robust fingerprint liveness system for LivDet 2025 (ALD).</span>
                    </li>
                    <li>
                      <i class="bi bi-check-circle"></i>
                      <span>Experience with EER, APCER, BPCER, IMS and challenge-style protocols.</span>
                    </li>
                    <li>
                      <i class="bi bi-check-circle"></i>
                      <span>Bridges research code, clean pipelines, and deployable Linux console apps.</span>
                    </li>
                  </ul>

                      <div class="cta-buttons">
                      
                        <a href="assets/papers/BIOVID_2025_LipAudio_Authentication.pdf" class="btn-primary" target="_blank">
                          <i class="bi bi-file-earmark-text"></i> BIOVID 2025 Publication
                        </a>
                      
                        <a href="assets/papers/LivDet2025_ALD_Fingerprint_Liveness.pdf" class="btn-secondary" target="_blank">
                          <i class="bi bi-file-earmark-text"></i> LivDet 2025 Paper
                        </a>
                      
                      </div>

                </div>
              </div>

              <!-- Contact Card -->
              <div class="contact-card" data-aos="fade-left" data-aos-delay="300">
                <h4>Open to Research &amp; Industry Roles</h4>
                <p>
                  I’m especially interested in teams working on authentication, fraud prevention, and trustworthy AI.
                </p>
                <div class="contact-methods">
                  <a href="mailto:govindaraju.venu@outlook.com" class="contact-item">
                    <i class="bi bi-envelope"></i>
                    <span>govindaraju.venu@outlook.com</span>
                  </a>
                  <a href="https://www.linkedin.com" class="contact-item">
                    <i class="bi bi-linkedin"></i>
                    <span>LinkedIn Profile</span>
                  </a>
                </div>
              </div>

            </div>
          </div>
          <!-- End Sidebar -->

          <!-- Main Content -->
          <div class="col-lg-8 order-lg-1">

            <!-- Overview -->
            <div class="service-overview" data-aos="fade-up" data-aos-delay="200">
              <div class="overview-header">
                <span class="badge">Biometrics &amp; Security</span>
                <h2>Two complementary biometric systems for real-world authentication</h2>
              </div>
              <p class="lead-text">
                My biometrics work is centered on two major projects:
              </p>
              <ul>
                <li><strong>BIOVID 2025 – Lip–Audio Multimodal Authentication:</strong> a dual-stream lip motion + speech
                  system for open-set user verification.</li>
                <li><strong>LivDet 2025 – Adversarial Liveness Detector (ALD):</strong> a fingerprint liveness and
                  identity verification pipeline integrating a CNN liveness model with a SIFT-based matcher and an Integrated
                  Match Score (IMS).</li>
              </ul>
              <p>
                Together, these systems cover <strong>multimodal verification</strong> (voice + video) and <strong>fingerprint
                  presentation attack detection</strong>, with a consistent focus on security, robustness, and protocol-compliant
                evaluation.
              </p>
            </div>

            <!-- Core focus areas -->
            <div class="features-grid" data-aos="fade-up" data-aos-delay="250">
              <h3 class="section-heading">Core focus areas in biometrics</h3>
              <div class="row g-4">

                <div class="col-md-6">
                  <div class="feature-box">
                    <div class="icon-wrapper">
                      <i class="bi bi-person-badge"></i>
                    </div>
                    <h4>Multimodal User Authentication</h4>
                    <p>
                      Design of dual-factor systems combining lip motion, speech, and fingerprints to increase robustness
                      over single-modality solutions.
                    </p>
                  </div>
                </div>

                <div class="col-md-6">
                  <div class="feature-box">
                    <div class="icon-wrapper">
                      <i class="bi bi-eye-slash"></i>
                    </div>
                    <h4>Liveness &amp; Anti-Spoofing</h4>
                    <p>
                      Experience with fingerprint liveness detection and presentation attack detection (PAD), focusing on
                      realistic spoof attempts and cross-sensor behaviour.
                    </p>
                  </div>
                </div>

                <div class="col-md-6">
                  <div class="feature-box">
                    <div class="icon-wrapper">
                      <i class="bi bi-diagram-2"></i>
                    </div>
                    <h4>Fusion &amp; Metric Learning</h4>
                    <p>
                      Fusion architectures (GMU, late fusion) and metric-learning heads (triplet loss, cosine thresholds)
                      for open-set verification in both projects.
                    </p>
                  </div>
                </div>

                <div class="col-md-6">
                  <div class="feature-box">
                    <div class="icon-wrapper">
                      <i class="bi bi-activity"></i>
                    </div>
                    <h4>Challenge-Style Evaluation</h4>
                    <p>
                      BIOVID and LivDet protocols, submission formats, and metrics such as EER, APCER, BPCER, ACE,
                      and IMS-based verification.
                    </p>
                  </div>
                </div>

              </div>
            </div>

            <!-- PROJECT 1: BIOVID – Lip–Audio -->
            <section class="workflow-section" id="biovid-workflow" data-aos="fade-up" data-aos-delay="300">
              <h3 class="section-heading">Project 1 – BIOVID 2025: Lip–Audio Multimodal Authentication</h3>
              <p>
                In BIOVID 2025, I developed a dual-stream lip–audio authentication system that verifies users based on
                synchronized lip motion and spoken passphrases. The system is designed for <strong>open-set verification</strong>,
                where unseen users at test time must be rejected reliably.
              </p>

              <div class="timeline">
                <div class="timeline-item">
                  <div class="timeline-marker">1</div>
                  <div class="timeline-content">
                    <h4>Data understanding &amp; protocol setup</h4>
                    <p>
                      Study of BIOVID dataset guidelines, user-disjoint folds, and open-set protocol. Defined enrolment
                      vs probe splits and ensured no identity leakage between train, validation, and test.
                    </p>
                    <span class="duration">Protocol-compliant design</span>
                  </div>
                </div>

                <div class="timeline-item">
                  <div class="timeline-marker">2</div>
                  <div class="timeline-content">
                    <h4>Lip ROI and audio preprocessing</h4>
                    <p>
                      For each sample: detect face &amp; lips, extract lip ROI sequences at a fixed frame rate, normalize
                      resolution, and preprocess speech waveforms (16 kHz, loudness normalization, trimming/silence handling).
                    </p>
                    <span class="duration">Clean, aligned inputs</span>
                  </div>
                </div>

                <div class="timeline-item">
                  <div class="timeline-marker">3</div>
                  <div class="timeline-content">
                    <h4>Dual-stream encoder design</h4>
                    <p>
                      Visual branch with <strong>ResNet3D-18 + BiGRU</strong> to capture articulation dynamics, and audio branch
                      based on a fine-tuned <strong>ECAPA-TDNN</strong> for robust speaker embeddings.
                    </p>
                    <span class="duration">Specialized encoders per modality</span>
                  </div>
                </div>

                <div class="timeline-item">
                  <div class="timeline-marker">4</div>
                  <div class="timeline-content">
                    <h4>GMU fusion &amp; metric learning</h4>
                    <p>
                      Concatenated audio–visual embeddings are fused via a <strong>Gated Multimodal Unit (GMU)</strong>, followed
                      by classification and embedding heads trained with <strong>binary cross-entropy + triplet loss</strong> for
                      open-set verification.
                    </p>
                    <span class="duration">Multimodal representation learning</span>
                  </div>
                </div>

                <div class="timeline-item">
                  <div class="timeline-marker">5</div>
                  <div class="timeline-content">
                    <h4>Thresholding &amp; evaluation</h4>
                    <p>
                      Compute cosine similarity between enrolment and probe embeddings, tune thresholds on validation folds,
                      and report Accuracy, EER, APCER, and BPCER under the official BIOVID scoring protocol.
                    </p>
                    <span class="duration">Open-set decision &amp; reporting</span>
                  </div>
                </div>
              </div>
            </section>

            <!-- MODEL ARCHITECTURES – BIOVID & shared -->
            <section class="section" id="model-architectures" data-aos="fade-up" data-aos-delay="350">
              <div class="section-title">
                <span class="subtitle">Technical Deep Dive</span>
                <h2>Model architectures across lip–audio &amp; fingerprint systems</h2>
                <p>
                  Below are the key architectures I implemented and adapted for the BIOVID lip–audio system and the LivDet
                  fingerprint liveness framework.
                </p>
              </div>

              <div class="row gy-4">
                <!-- Architecture 1: Lip visual -->
                <div class="col-lg-6">
                  <div class="feature-box">
                    <div class="icon-wrapper">
                      <i class="bi bi-camera-video"></i>
                    </div>
                    <h4>ResNet3D-18 + BiGRU (Lip Visual Encoder)</h4>
                    <p>
                      Spatio-temporal encoder for lip ROI sequences, used in BIOVID lip–audio authentication.
                    </p>
                    <ul>
                      <li>3D convolutions model frame-level motion and lip shape changes.</li>
                      <li>BiGRU layers aggregate temporal context in both directions.</li>
                      <li>Produces compact embeddings suitable for metric learning.</li>
                    </ul>
                  </div>
                </div>

                <!-- Architecture 2: Lip audio -->
                <div class="col-lg-6">
                  <div class="feature-box">
                    <div class="icon-wrapper">
                      <i class="bi bi-soundwave"></i>
                    </div>
                    <h4>ECAPA-TDNN (Speech Encoder)</h4>
                    <p>
                      Audio encoder fine-tuned on passphrase-level speech for BIOVID, generating robust speaker embeddings.
                    </p>
                    <ul>
                      <li>Attentive statistics pooling for discriminative utterance-level features.</li>
                      <li>Resilient to short recordings and moderate background noise.</li>
                      <li>Seamlessly integrated with the GMU fusion module.</li>
                    </ul>
                  </div>
                </div>

                <!-- Architecture 3: Fusion -->
                <div class="col-lg-6">
                  <div class="feature-box">
                    <div class="icon-wrapper">
                      <i class="bi bi-diagram-3"></i>
                    </div>
                    <h4>Gated Multimodal Unit (GMU Fusion)</h4>
                    <p>
                      Fusion block that adaptively weights lip and audio embeddings based on their reliability per sample.
                    </p>
                    <ul>
                      <li>Learned gates control the contribution of each modality.</li>
                      <li>Improves performance when one modality is noisy or partially corrupted.</li>
                      <li>Central to the BIOVID lip–audio verification pipeline.</li>
                    </ul>
                  </div>
                </div>

                <!-- Architecture 4: Fingerprint CNN (ALD) -->
                <div class="col-lg-6">
                  <div class="feature-box">
                    <div class="icon-wrapper">
                      <i class="bi bi-fingerprint"></i>
                    </div>
                    <h4>EfficientNet-B6 Liveness Network (ALD)</h4>
                    <p>
                      Deep CNN backbone used in the LivDet 2025 Adversarial Liveness Detector (ALD) to estimate liveness
                      scores for fingerprints.
                    </p>
                    <ul>
                      <li>Trained in three stages (clean, adversarial, combined) for robustness.</li>
                      <li>Outputs calibrated liveness scores in [0, 1].</li>
                      <li>Forms the core of the fingerprint liveness detection pipeline.</li>
                    </ul>
                  </div>
                </div>
              </div>
            </section>

            <!-- ARCHITECTURE DIAGRAMS – BIOVID + ALD -->
            <section class="section" id="architecture-diagrams" data-aos="fade-up" data-aos-delay="400">

              <div class="section-title">
                <span class="subtitle">System View</span>
                <h2>Architecture diagrams for both projects</h2>
                <p>
                  High-level diagrams showing how the lip–audio and fingerprint systems are structured – from raw signals
                  to verification scores.
                </p>
              </div>

              <div class="row gy-5">

                <!-- Lip–Audio Multimodal Architecture -->
                <div class="col-lg-12">
                  <div class="service-image-showcase">
                    <!-- Export your BIOVID diagram to this path -->
                    <img src="assets/img/services/Slide1.png"
                      alt="Lip–Audio Multimodal Authentication Architecture" class="img-fluid main-image">

                    <div class="image-overlay">
                      <div class="tech-stack">
                        <span class="tech-item">ResNet3D-18</span>
                        <span class="tech-item">BiGRU</span>
                        <span class="tech-item">ECAPA-TDNN</span>
                        <span class="tech-item">GMU Fusion</span>
                        <span class="tech-item">Triplet + BCE</span>
                      </div>
                    </div>
                  </div>

                  <div class="mt-3">
                    <h4>BIOVID lip–audio multimodal verification pipeline</h4>
                    <p class="mb-2">
                      The BIOVID system combines visual and audio streams for robust user verification:
                    </p>
                    <ul>
                      <li><strong>Visual branch:</strong> lip ROI sequence → <em>ResNet3D-18</em> →
                        <em>BiGRU</em> → visual embedding.</li>
                      <li><strong>Audio branch:</strong> passphrase waveform → <em>ECAPA-TDNN</em> →
                        speaker embedding.</li>
                      <li><strong>Fusion:</strong> concatenated embeddings → <em>GMU</em> for adaptive audio–visual
                        weighting.</li>
                      <li><strong>Heads:</strong> shared representation → classification (BCE) + embedding head
                        (triplet loss).</li>
                      <li><strong>Decision:</strong> cosine similarity + calibrated threshold for open-set accept / reject.</li>
                    </ul>
                  </div>
                </div>

               

                  <div class="mt-3">
                    <h4>LivDet 2025 – Adversarial Liveness Detector (ALD) pipeline</h4>
                    <p class="mb-2">
                      The ALD system combines CNN-based liveness detection with SIFT-based identity matching:
                    </p>
                    <ul>
                      <li><strong>Data preparation:</strong> grayscale normalization, padding/resize, and sensor-aware
                        indexing.</li>
                      <li><strong>Liveness network:</strong> EfficientNet-B6 trained in three stages (ALD_A/B/C) on
                        clean and adversarial samples.</li>
                      <li><strong>Identity matching:</strong> SIFT feature extraction, matching with Lowe’s ratio test,
                        and RANSAC-based inlier estimation.</li>
                      <li><strong>Fusion:</strong> liveness score (LS) + match value (MV) → rule-based
                        <em>Integrated Match Score (IMS)</em> for final decision.</li>
                      <li><strong>Deployment:</strong> Linux console app that outputs LS and IMS for each probe–template pair.</li>
                    </ul>
                  </div>
                </div>

                 <!-- Fingerprint ALD Architecture -->
                <div class="col-lg-12 mt-4">
                  <div class="service-image-showcase">
                    <!-- Export your ALD pipeline diagram to this path -->
                    <img src="assets/img/services/ald_pipeline_one.png"
                      alt="Fingerprint Adversarial Liveness Detector (ALD) Architecture" class="img-fluid main-image">

                    <div class="image-overlay">
                      <div class="tech-stack">
                        <span class="tech-item">EfficientNet-B6</span>
                        <span class="tech-item">Adversarial Training</span>
                        <span class="tech-item">SIFT Matching</span>
                        <span class="tech-item">Liveness Score (LS)</span>
                        <span class="tech-item">Integrated Match Score (IMS)</span>
                      </div>
                    </div>
                  </div>

              </div>
            </section>

            <!-- PROJECT 2: LivDet – Fingerprint Liveness -->
            <section class="workflow-section" id="livdet-workflow" data-aos="fade-up" data-aos-delay="450">
              <h3 class="section-heading">Project 2 – LivDet 2025: Adversarial Liveness Detector for Fingerprints</h3>
              <p>
                In LivDet 2025, I co-developed the <strong>Adversarial Liveness Detector (ALD)</strong>, an integrated
                fingerprint pipeline that jointly estimates liveness and identity similarity through an <strong>Integrated
                  Match Score (IMS)</strong>.
              </p>

              <div class="timeline">
                <div class="timeline-item">
                  <div class="timeline-marker">1</div>
                  <div class="timeline-content">
                    <h4>Dataset normalization &amp; sensor handling</h4>
                    <p>
                      Unified preprocessing across multiple sensors: grayscale conversion, padding/resize to a fixed
                      resolution, per-sensor intensity normalization, and train/validation splits stratified by sensor and
                      class.
                    </p>
                    <span class="duration">Consistent input space</span>
                  </div>
                </div>

                <div class="timeline-item">
                  <div class="timeline-marker">2</div>
                  <div class="timeline-content">
                    <h4>Stage ALD_A – Clean training</h4>
                    <p>
                      Training EfficientNet-B6 on clean fingerprints with light augmentations, using binary cross-entropy
                      and a contrastive/metric regularizer to learn discriminative live vs spoof representations.
                    </p>
                    <span class="duration">Baseline liveness model</span>
                  </div>
                </div>

                <div class="timeline-item">
                  <div class="timeline-marker">3</div>
                  <div class="timeline-content">
                    <h4>Stage ALD_B – Adversarial companion training</h4>
                    <p>
                      Generation of adversarial fingerprints (DeepFool-style perturbations) and joint training on clean +
                      adversarial data to harden the network against subtle spoof perturbations.
                    </p>
                    <span class="duration">Robustness via adversarial samples</span>
                  </div>
                </div>

                <div class="timeline-item">
                  <div class="timeline-marker">4</div>
                  <div class="timeline-content">
                    <h4>Stage ALD_C – Clean + adversarial retraining</h4>
                    <p>
                      Final retraining on the combined dataset without traditional augmentations, letting adversarial
                      diversity drive invariance. Models are selected based on ACE/EER and cross-sensor consistency.
                    </p>
                    <span class="duration">Generalization across sensors</span>
                  </div>
                </div>

                <div class="timeline-item">
                  <div class="timeline-marker">5</div>
                  <div class="timeline-content">
                    <h4>SIFT identity matching &amp; IMS fusion</h4>
                    <p>
                      For each probe–template pair, SIFT descriptors are matched, inliers estimated via RANSAC to compute a
                      Match Value (MV), which is then fused with the liveness score (LS) to produce the final IMS for
                      decision-making.
                    </p>
                    <span class="duration">Joint liveness + identity decision</span>
                  </div>
                </div>

                <div class="timeline-item">
                  <div class="timeline-marker">6</div>
                  <div class="timeline-content">
                    <h4>Console application &amp; submission</h4>
                    <p>
                      Implementation of a Linux console app that reads probe–template lists, runs the ALD pipeline, and
                      outputs LS and IMS in the exact format required by the LivDet 2025 organizers.
                    </p>
                    <span class="duration">Reproducible challenge submission</span>
                  </div>
                </div>
              </div>
            </section>

            <!-- Datasets & Tasks -->
            <div class="tech-details" data-aos="fade-up" data-aos-delay="500">
              <h3 class="section-heading">Datasets &amp; biometric tasks I’ve worked on</h3>
              <div class="tech-categories">

                <div class="tech-category">
                  <h5>BIOVID Challenge 2025 – Lip–Audio Authentication</h5>
                  <div class="tech-tags">
                    <span>Dual-factor lip–audio user verification</span>
                    <span>User-disjoint training &amp; test folds</span>
                    <span>Open-set verification with EER &amp; APCER/BPCER</span>
                  </div>
                </div>

                <div class="tech-category">
                  <h5>LivDet 2025 – Fingerprint Liveness &amp; IMS</h5>
                  <div class="tech-tags">
                    <span>Live vs spoof fingerprint classification</span>
                    <span>Adversarially robust liveness scores (LS)</span>
                    <span>Integrated Match Score (IMS) combining LS + SIFT match</span>
                  </div>
                </div>

                <div class="tech-category">
                  <h5>Multimodal research prototypes</h5>
                  <div class="tech-tags">
                    <span>Vision + audio combinations</span>
                    <span>Embedding-based verification</span>
                    <span>Cross-modal consistency checks</span>
                  </div>
                </div>

              </div>
            </div>

            <!-- Architectures & Methods summary -->
            <div class="tech-details" data-aos="fade-up" data-aos-delay="550">
              <h3 class="section-heading">Architectures, methods &amp; implementation stack</h3>
              <div class="tech-categories">

                <div class="tech-category">
                  <h5>Visual &amp; audio streams (BIOVID)</h5>
                  <div class="tech-tags">
                    <span>ResNet3D-18</span>
                    <span>BiGRU</span>
                    <span>ECAPA-TDNN</span>
                    <span>GMU fusion</span>
                  </div>
                </div>

                <div class="tech-category">
                  <h5>Fingerprint liveness (LivDet 2025 ALD)</h5>
                  <div class="tech-tags">
                    <span>EfficientNet-B6</span>
                    <span>Adversarial training stages (ALD_A/B/C)</span>
                    <span>Contrastive / metric regularization</span>
                  </div>
                </div>

                <div class="tech-category">
                  <h5>Fusion &amp; verification</h5>
                  <div class="tech-tags">
                    <span>Triplet loss</span>
                    <span>Binary cross-entropy</span>
                    <span>Cosine similarity thresholds</span>
                    <span>SIFT-based matching &amp; IMS fusion</span>
                  </div>
                </div>

                <div class="tech-category">
                  <h5>Implementation stack</h5>
                  <div class="tech-tags">
                    <span>Python</span>
                    <span>PyTorch</span>
                    <span>OpenCV (SIFT/RANSAC)</span>
                    <span>Experiment tracking &amp; k-fold CV</span>
                    <span>Linux console tools</span>
                  </div>
                </div>

              </div>
            </div>

            <!-- Metrics & Results -->
            <div class="features-grid" data-aos="fade-up" data-aos-delay="600">
              <h3 class="section-heading">How I evaluate biometric systems</h3>
              <div class="row g-4">
                <div class="col-md-6">
                  <div class="feature-box">
                    <div class="icon-wrapper">
                      <i class="bi bi-graph-down-arrow"></i>
                    </div>
                    <h4>Verification-centric metrics</h4>
                    <p>
                      I use metrics like EER, ROC curves, and open-set verification accuracy to evaluate both BIOVID
                      lip–audio and fingerprint IMS outputs, tuning thresholds on validation sets and reporting final scores
                      on held-out test data.
                    </p>
                  </div>
                </div>

                <div class="col-md-6">
                  <div class="feature-box">
                    <div class="icon-wrapper">
                      <i class="bi bi-shield-check"></i>
                    </div>
                    <h4>Security vs usability trade-offs</h4>
                    <p>
                      For liveness and PAD, I monitor APCER/BPCER, ACE, and IMS distributions to balance security
                      (blocking attacks) with usability (minimizing false rejections of genuine users).
                    </p>
                  </div>
                </div>

                <div class="col-12">
                  <div class="feature-box">
                    <div class="icon-wrapper">
                      <i class="bi bi-bar-chart"></i>
                    </div>
                    <h4>Challenge-style robustness</h4>
                    <p>
                      Both systems are built to survive <strong>realistic challenge conditions</strong> – unseen users, cross-sensor
                      generalization, and adversarially perturbed data – rather than overfitting to a single dataset split.
                    </p>
                  </div>
                </div>
              </div>
            </div>

            <!-- Personal Note -->
            <div class="testimonial-section" data-aos="fade-up" data-aos-delay="650">
              <div class="testimonial-card">
                <blockquote>
                  “For me, biometric systems are not only about high accuracy on a benchmark. They must withstand noisy
                  devices, new users, and creative attackers. That’s why in both BIOVID and LivDet I combine strong deep
                  learning architectures with careful protocols, metrics, and a security-first mindset.”
                </blockquote>
                <div class="client-info">
                  <img src="assets/img/profile/profile-square-3.webp" alt="Venu Govindaraju" class="client-avatar">
                  <div class="client-details">
                    <h5>Venu Siddapura Govindaraju</h5>
                    <p>AI Researcher &amp; Data Engineer</p>
                  </div>
                </div>
              </div>
            </div>

          </div>
          <!-- End Main Content -->

        </div>

      </div>
    </section>

  </main>

  <!-- Footer -->
  <footer id="footer" class="footer">
    <div class="container footer-top">
      <div class="row gy-4">
        <div class="col-lg-5 col-md-12 footer-about">
          <a href="index.html" class="logo d-flex align-items-center">
            <span class="sitename">Venu Govindaraju</span>
          </a>
          <p>
            AI Researcher and Data Engineer working on multimodal biometrics, trustworthy AI, and scalable data
            platforms.
          </p>
          <div class="social-links d-flex mt-4">
            <a href="#"><i class="bi bi-twitter-x"></i></a>
            <a href="#"><i class="bi bi-facebook"></i></a>
            <a href="#"><i class="bi bi-instagram"></i></a>
            <a href="#"><i class="bi bi-linkedin"></i></a>
          </div>
        </div>

        <div class="col-lg-2 col-6 footer-links">
          <h4>Navigation</h4>
          <ul>
            <li><a href="index.html#hero">Home</a></li>
            <li><a href="index.html#about">About me</a></li>
            <li><a href="index.html#resume">Experience</a></li>
            <li><a href="index.html#services">Expertise</a></li>
            <li><a href="index.html#portfolio">Projects</a></li>
          </ul>
        </div>

        <div class="col-lg-2 col-6 footer-links">
          <h4>Focus areas</h4>
          <ul>
            <li><a href="expertise-ml.html">Applied ML</a></li>
            <li><a href="expertise-data-engineering.html">Data Engineering</a></li>
            <li><a href="expertise-biometrics.html">Biometrics &amp; Security</a></li>
          </ul>
        </div>

        <div class="col-lg-3 col-md-12 footer-contact text-center text-md-start">
          <h4>Contact</h4>
          <p>Naples</p>
          <p>Italy</p>
          <p class="mt-4"><strong>Phone:</strong> <span>+39 334 896 1888</span></p>
          <p><strong>Email:</strong> <span>govindaraju.venu@outlook.com</span></p>
        </div>

      </div>
    </div>

    <div class="container copyright text-center mt-4">
      <p>© <span>Copyright</span> <strong class="px-1 sitename">Venu Govindaraju</strong> <span>All Rights
          Reserved</span></p>
      <div class="credits">
        Template base by <a href="https://bootstrapmade.com/">BootstrapMade</a> · Customized by Venu
        Govindaraju
      </div>
    </div>
  </footer>

  <!-- Scroll Top -->
  <a href="#" id="scroll-top" class="scroll-top d-flex align-items-center justify-content-center">
    <i class="bi bi-arrow-up-short"></i>
  </a>

  <!-- Preloader -->
  <div id="preloader"></div>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/aos/aos.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/imagesloaded/imagesloaded.pkgd.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>

  <!-- Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>
